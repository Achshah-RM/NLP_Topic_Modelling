# Consumer Complaints Topic Modeling Project
This repository contains the code and resources for a Natural Language Processing (NLP) project focused on analyzing customer complaints data using unsupervised topic modeling techniques.

## Dataset
The dataset used in this project is sourced from Kaggle:
[Consumer Financial Protection Bureau (CFPB) Complaints Dataset](https://www.kaggle.com/datasets/adhamelkomy/bank-customer-complaint-analysis?select=complaints.csv).

- **Size**: 162,422 rows
- **Content**: Narrative texts detailing customer complaints about financial products and services.
- **Note**: Labels (product categories) were removed to maintain the unsupervised nature of the analysis.

## Repository Structure
```plaintext
project
├── notebooks/
│   └── analysis.ipynb   # Jupyter Notebook containing the code and analysis
├── results/
│   ├── plots/           # Graphical outputs such as bar charts, word clouds, etc.
│   ├── topics/          # Top words generated by each model saved as .txt files
├── requirements.txt     # List of dependencies
├── README.md            # Project overview
├── .gitignore           # Files and directories to be ignored by Git
```

### Ignored Files/Directories
- **data/**: Contains the original and preprocessed datasets (excluded due to size).
- **venv/**: Virtual environment directory.

## Tools and Libraries
- **Preprocessing**: `spaCy`, `NLTK`
- **Vectorization**: `scikit-learn` for Bag of Words (BoW) and TF-IDF
- **Modeling**: `gensim` (LDA), `scikit-learn` (NMF), `BERTopic`
- **Visualization**: `pyLDAvis`, `Matplotlib`, `WordCloud`
- **Evaluation**: `gensim` Coherence Model (C_v)

## Instructions to Run the Project

### 1. Clone the Repository
   ```bash
   git clone <repository-url>
   cd <repository-folder>
   ```

### 2. Set Up Virtual Environment
   ```bash
   # Create a virtual environment
   python -m venv venv
    
   # Activate the environment
   
   # Windows
   venv\Scripts\activate
   
   # macOS/Linux
   source venv/bin/activate
    
   # Install dependencies
   pip install -r requirements.txt
   ```
### 3. Open the Notebook
   Use your preferred IDE (e.g., Jupyter Notebook or VS Code) to open `notebooks/analysis.ipynb`.
   ```bash
   # For Jupyter Notebook
   jupyter notebook notebooks/analysis.ipynb
   ```
### 4. Project Steps in the Notebook
  The Jupyter Notebook contains:
  
  - **Data Preprocessing**:
    - Tokenization, lemmatization, stop-word removal, and text normalization.
  - **Vectorization**:
    - Bag of Words (BoW) and TF-IDF.
  - **Topic Modeling**:
    - Implementations of LDA, NMF, and BERTopic.
  - **Evaluation and Visualizations**:
    - Coherence score (C_v), Word clouds, pyLDAvis interactive plots, and bar charts.

### 5. Results
Key findings, coherence scores, and interpretability evaluations are documented within the notebook.

## Acknowledgments
This project is part of the course requirement for "Data Analysis" under the guidance of Dr. Frank Passing at IU International University of Applied Science, Germany. The insights gained are meant to enhance decision-making for consumer grievance redressal systems.

